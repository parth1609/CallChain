{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089d3190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CallChain.audio.transcribe import AudioTranscriber\n",
    "from CallChain.audio.clients import GroqAudioClient\n",
    "from CallChain.audio.config import AudioConfig\n",
    "from CallChain.audio.processor import AudioProcessor\n",
    "\n",
    "\n",
    "from CallChain.models.groq import GroqModel\n",
    "model_name=\"openai/gpt-oss-20b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497a31d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Explain what a large language model is in one sentence.\n",
      "\n",
      "Response: A large language model is a deep neural network trained on massive amounts of text data to generate, understand, and respond to human language with contextually relevant outputs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GroqModel(model_name=model_name)\n",
    "\n",
    "# Generate response\n",
    "prompt = \"Explain what a large language model is in one sentence.\"\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "\n",
    "response = model.generate(prompt)\n",
    "print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c112457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template: You are a {role}. Write a {length} {content_type} about {topic}.\n",
      "\n",
      "Formatted Prompt: You are a professional writer. Write a short summary about quantum computing.\n",
      "\n",
      "Response: **Quantum Computing â€“ A Brief Overview**\n",
      "\n",
      "Quantum computing harnesses the principles of quantum mechanicsâ€”superposition, entanglement, and tunnelingâ€”to process information in fundamentally new ways. While classical computers encode data as bits that are either 0 or 1, a quantum computer uses *qubits* that can exist in a superposition of both states simultaneously. This property, coupled with entanglement (where qubits become linked across distances), allows a quantum processor to explore many computational paths in parallel.\n",
      "\n",
      "The fieldâ€™s most celebrated algorithms illustrate this power. Shorâ€™s algorithm factorizes large integers exponentially faster than any known classical routine, threatening current publicâ€‘key cryptography. Groverâ€™s search algorithm offers a quadratic speedâ€‘up for unstructured database queries. Beyond cryptography, quantum computers promise breakthroughs in materials science, drug discovery, optimization, and machine learning by simulating complex quantum systems that are infeasible for classical machines.\n",
      "\n",
      "However, practical quantum advantage remains a frontier. Qubits are exquisitely fragile, requiring extreme isolation and error correction to maintain coherence. Building faultâ€‘tolerant, largeâ€‘scale quantum machines demands advances in hardware, control electronics, and theoretical protocols. As research continues, quantum computing stands poised to transform computation, but its full impact will unfold over the coming decades.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from CallChain.prompts import StringPromptTemplate\n",
    "from CallChain.models import StringPromptTemplate,PromptTemplate\n",
    "\n",
    "template = StringPromptTemplate(\n",
    "            \"You are a {role}. Write a {length} {content_type} about {topic}.\"\n",
    "        )\n",
    "\n",
    "formatted_prompt = template.format(\n",
    "            role=\"professional writer\",\n",
    "            length=\"short\",\n",
    "            content_type=\"summary\",\n",
    "            topic=\"quantum computing\"\n",
    "        )\n",
    "\n",
    "print(f\"Template: {template.template}\")\n",
    "print(f\"\\nFormatted Prompt: {formatted_prompt}\\n\")\n",
    "        \n",
    "# Use it with a model\n",
    "model = GroqModel(model_name=model_name)\n",
    "response = model.generate(formatted_prompt)\n",
    "print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282574a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'topic': 'benefits of renewable energy'}\n",
      "\n",
      "--- Step: analysis ---\n",
      "Prompt: Analyze this topic and provide 3 key points: benefits of renewable energy\n",
      "Result:\n",
      "**Brief analysis**\n",
      "\n",
      "Renewable energyâ€”solar, wind, hydro, geothermal, and biomassâ€”offers a suite of advantages that extend beyond simply replacing fossil fuels. While the environmental case is often the most discussed, the true value of renewables emerges from their ability to provide cleaner air, economic resilience, and energy independence, all of which feed into longâ€‘term sustainability and societal wellâ€‘being.\n",
      "\n",
      "---\n",
      "\n",
      "### 3 Key Benefits of Renewable Energy\n",
      "\n",
      "| # | Benefit | Why It Matters |\n",
      "|---|---------|----------------|\n",
      "| **1. Climate and Airâ€‘Quality Protection** | Renewable sources emit little to no greenhouse gases or local pollutants after installation. | Reduces the rate of global warming, mitigates extreme weather events, and improves public health by lowering respiratory illnesses linked to air pollution. |\n",
      "| **2. Economic Growth & Job Creation** | The renewables sector is laborâ€‘intensive during manufacturing, installation, and maintenance. | Generates millions of jobs worldwide, stimulates local economies, and can lower overall energy costs as technology matures and economies of scale take effect. |\n",
      "| **3. Energy Security & Resilience** | Distributed renewable generation (e.g., rooftop solar, community wind) diversifies the supply mix and can be stored or dispatched on demand. | Lessens dependence on imported fuels, reduces vulnerability to price spikes or geopolitical disruptions, and enhances grid stability through advanced storage and smartâ€‘grid integration. |\n",
      "\n",
      "These points illustrate how renewable energy is not just an environmental choice but a strategic investment in healthier communities, robust economies, and a stable, secure energy future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from CallChain import Chain\n",
    "\n",
    "# Create a chain with multiple steps\n",
    "model = GroqModel(model_name=model_name)\n",
    "\n",
    "chain = Chain()\n",
    "chain.step(\n",
    "    \"analysis\",\n",
    "    model,\n",
    "    prompt_template=\"Analyze this topic and provide 3 key points: {topic}\"\n",
    ")\n",
    " \n",
    "\n",
    "# Execute the chain\n",
    "config = {\"topic\": \"benefits of renewable energy\"}\n",
    "print(f\"Input: {config}\\n\")\n",
    "\n",
    "result = chain.run(**config)\n",
    "print(f\"Result:\\n{result['analysis']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6accc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step: person ---\n",
      "Prompt: who is prime of: india\n",
      "--- Step: age ---\n",
      "Prompt: what is the age of Narendraâ€¯Modi. in intger only?\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "chain = Chain()\n",
    "\n",
    "# Step 1: Analysis\n",
    "chain.step(\n",
    "    \"person\",  # <--- This name is important!\n",
    "    model,\n",
    "    prompt_template=\"who is prime of: {topic}\",\n",
    ")\n",
    "\n",
    "# Step 2: Physics Relation (Uses output from 'analysis')\n",
    "chain.step(\n",
    "    \"age\",\n",
    "    model,\n",
    "    prompt_template=\"what is the age of {person} in intger only?\"\n",
    ")\n",
    "\n",
    "# Run it\n",
    "result = chain.run(topic=\"india\")\n",
    "print(result['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a432b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AudioTranscriber initialized\n",
      "ðŸ“ Configuration:\n",
      "   - Model: whisper-large-v3-turbo\n",
      "   - Language: en\n",
      "   - Sample Rate: 16000 Hz\n",
      "   - Normalization: True\n",
      "   - Trim Silence: True\n",
      "   - Noise Reduction: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple initialization (backward compatible)\n",
    "transcriber = AudioTranscriber()\n",
    "\n",
    "print(\"âœ… AudioTranscriber initialized\")\n",
    "# This is default configuration, anyone can change it\n",
    "print(\"ðŸ“ Configuration:\")\n",
    "print(f\"   - Model: {transcriber.config.model}\")\n",
    "print(f\"   - Language: {transcriber.config.language}\")\n",
    "print(f\"   - Sample Rate: {transcriber.config.target_sr} Hz\")\n",
    "print(f\"   - Normalization: {transcriber.config.normalize}\")\n",
    "print(f\"   - Trim Silence: {transcriber.config.trim_silence}\")\n",
    "print(f\"   - Noise Reduction: {transcriber.config.noise_reduction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcad9972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AudioTranscriber initialized with custom config\n",
      "ðŸ“ Configuration:\n",
      "   - Model: whisper-large-v3-turbo\n",
      "   - Language: en\n",
      "   - Sample Rate: 16000 Hz\n",
      "   - Normalization: True\n",
      "   - Trim Silence: True\n",
      "   - Noise Reduction: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Advanced configuration using AudioConfig\n",
    "config = AudioConfig(\n",
    "    model=\"whisper-large-v3-turbo\",\n",
    "    language=\"en\",\n",
    "    target_sr=16000,\n",
    "    normalize=True,\n",
    "    trim_silence=True,\n",
    "    noise_reduction=True  # Requires noisereduce package\n",
    ")\n",
    "\n",
    "transcriber = AudioTranscriber(config=config)\n",
    "\n",
    "print(\"âœ… AudioTranscriber initialized with custom config\")\n",
    "print(\"ðŸ“ Configuration:\")\n",
    "print(f\"   - Model: {config.model}\")\n",
    "print(f\"   - Language: {config.language}\")\n",
    "print(f\"   - Sample Rate: {config.target_sr} Hz\")\n",
    "print(f\"   - Normalization: {config.normalize}\")\n",
    "print(f\"   - Trim Silence: {config.trim_silence}\")\n",
    "print(f\"   - Noise Reduction: {config.noise_reduction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55c70902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Audio transcriber ready\n",
      "âœ… LLM model ready\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup audio transcriber\n",
    "audio_config = AudioConfig(\n",
    "    model=\"whisper-large-v3-turbo\",\n",
    "    normalize=True,\n",
    "    trim_silence=True\n",
    ")\n",
    "transcriber = AudioTranscriber(config=audio_config)\n",
    "print(\"âœ… Audio transcriber ready\")\n",
    "\n",
    "# Step 2: Setup LLM model\n",
    "llm_model = GroqModel(model_name=model_name)\n",
    "print(\"âœ… LLM model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c7e4c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transcriber initialized with Custom Client\n"
     ]
    }
   ],
   "source": [
    "class MockAudioClient:\n",
    "    def transcribe(self, audio_file, model, language, temperature):\n",
    "        return \"This is a simulated transcription from a custom client.\"\n",
    "\n",
    "# Inject the custom client\n",
    "custom_client = MockAudioClient()\n",
    "transcriber = AudioTranscriber(client=custom_client)\n",
    "\n",
    "print(\"âœ… Transcriber initialized with Custom Client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8647570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
